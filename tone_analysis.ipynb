{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "negative tone",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "__MBZqATp_M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Lp0SW7R9R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtYHf4IoW3mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url='https://raw.githubusercontent.com/Prateek190/s1/master/LoughranMcDonald_MasterDictionary_2018.csv'\n",
        "df= pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OaaTVPieoql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "5b462d1b-96d3-4fc6-ad41-2ab5e2f3edba"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Sequence Number</th>\n",
              "      <th>Word Count</th>\n",
              "      <th>Word Proportion</th>\n",
              "      <th>Average Proportion</th>\n",
              "      <th>Std Dev</th>\n",
              "      <th>Doc Count</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Uncertainty</th>\n",
              "      <th>Litigious</th>\n",
              "      <th>Constraining</th>\n",
              "      <th>Superfluous</th>\n",
              "      <th>Interesting</th>\n",
              "      <th>Modal</th>\n",
              "      <th>Irr_Verb</th>\n",
              "      <th>Harvard_IV</th>\n",
              "      <th>Syllables</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AARDVARK</td>\n",
              "      <td>1</td>\n",
              "      <td>277</td>\n",
              "      <td>1.480000e-08</td>\n",
              "      <td>1.240000e-08</td>\n",
              "      <td>3.560000e-06</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AARDVARKS</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1.600000e-10</td>\n",
              "      <td>9.730000e-12</td>\n",
              "      <td>9.860000e-09</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABACI</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>4.280000e-10</td>\n",
              "      <td>1.390000e-10</td>\n",
              "      <td>6.230000e-08</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABACK</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>6.410000e-10</td>\n",
              "      <td>3.160000e-10</td>\n",
              "      <td>9.380000e-08</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABACUS</td>\n",
              "      <td>5</td>\n",
              "      <td>7250</td>\n",
              "      <td>3.870000e-07</td>\n",
              "      <td>3.680000e-07</td>\n",
              "      <td>3.370000e-05</td>\n",
              "      <td>914</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Word  Sequence Number  Word Count  ...  Harvard_IV  Syllables     Source\n",
              "0   AARDVARK                1         277  ...           0          2  12of12inf\n",
              "1  AARDVARKS                2           3  ...           0          2  12of12inf\n",
              "2      ABACI                3           8  ...           0          3  12of12inf\n",
              "3      ABACK                4          12  ...           0          2  12of12inf\n",
              "4     ABACUS                5        7250  ...           0          3  12of12inf\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHiCowRFfFNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "433b63b4-15e7-42a6-cd1e-debccb851be9"
      },
      "source": [
        "dfn=df[df['Negative']!=0]\n",
        "dfn.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Sequence Number</th>\n",
              "      <th>Word Count</th>\n",
              "      <th>Word Proportion</th>\n",
              "      <th>Average Proportion</th>\n",
              "      <th>Std Dev</th>\n",
              "      <th>Doc Count</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Uncertainty</th>\n",
              "      <th>Litigious</th>\n",
              "      <th>Constraining</th>\n",
              "      <th>Superfluous</th>\n",
              "      <th>Interesting</th>\n",
              "      <th>Modal</th>\n",
              "      <th>Irr_Verb</th>\n",
              "      <th>Harvard_IV</th>\n",
              "      <th>Syllables</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ABANDON</td>\n",
              "      <td>10</td>\n",
              "      <td>103050</td>\n",
              "      <td>5.510000e-06</td>\n",
              "      <td>4.950000e-06</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>56605</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ABANDONED</td>\n",
              "      <td>11</td>\n",
              "      <td>201921</td>\n",
              "      <td>1.080000e-05</td>\n",
              "      <td>1.090000e-05</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>95651</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ABANDONING</td>\n",
              "      <td>12</td>\n",
              "      <td>18985</td>\n",
              "      <td>1.010000e-06</td>\n",
              "      <td>9.150000e-07</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>11846</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ABANDONMENT</td>\n",
              "      <td>13</td>\n",
              "      <td>229801</td>\n",
              "      <td>1.230000e-05</td>\n",
              "      <td>1.190000e-05</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>79689</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ABANDONMENTS</td>\n",
              "      <td>14</td>\n",
              "      <td>9276</td>\n",
              "      <td>4.960000e-07</td>\n",
              "      <td>6.340000e-07</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>4730</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>12of12inf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Word  Sequence Number  Word Count  ...  Harvard_IV  Syllables     Source\n",
              "9        ABANDON               10      103050  ...           1          3  12of12inf\n",
              "10     ABANDONED               11      201921  ...           2          3  12of12inf\n",
              "11    ABANDONING               12       18985  ...           2          4  12of12inf\n",
              "12   ABANDONMENT               13      229801  ...           1          4  12of12inf\n",
              "13  ABANDONMENTS               14        9276  ...           2          4  12of12inf\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5m-yW31g4tY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url='https://github.com/Prateek190/s1/raw/master/IOC.csv'\n",
        "dffirm= pd.read_csv(url)\n",
        "url1='https://github.com/Prateek190/s2/raw/master/IOC.csv'\n",
        "url2='https://raw.githubusercontent.com/Prateek190/s3/master/IOC.csv'\n",
        "dffirm1= pd.read_csv(url1)\n",
        "dffirm2= pd.read_csv(url2)\n",
        "df1=pd.concat([dffirm,dffirm1])\n",
        "dff= pd.concat([df1,dffirm2])\n",
        "dff.dropna(inplace=True)\n",
        "\n",
        "dff['Date'] = dff['Date'].astype(str)\n",
        "#dff['Date'] = pd.to_datetime(dff.Date,errors='ignore')\n",
        "dffnx= dff.set_index('Date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QegVwVwKqgRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "m=dfn['Word'].to_list()\n",
        "nwords=[w.lower() for w in m]\n",
        "nwords\n",
        "\n",
        "  #a+=datetime.timedelta(days=1)\n",
        "  #a.isoformat()\n",
        "companies=[\"Adani\", \"Asian Paints\", \"Axis Bank\", \"Bajaj Auto\", \"Bajaj Finance\", \"Bajaj Finserv\", \"Airtel\", \"Bharti Infratel\", \"BPCL\", \"Britannia\", \"Cipla\", \"Coal India\", \"Reddy\", \"Eicher\", \"GAIL\", \"Grasim\", \"HCL\", \"HDFC\", \"HDFC Bank\", \"Hero Moto\", \"Hindalco\", \"Unilever\", \"ICICI\", \"IndusInd\", \"Infosys\", \"IOC\", \"ITC\", \"JSW\", \"Kotak\", \"Larsen\", \"Mahindra  Mahindra\", \"Maruti\", \"Nestle\", \"NTPC\", \"ONGC\", \"PowerGrid\", \"Reliance\", \"Shree Cement\", \"State Bank\", \"Sun Pharma\", \"TCS\", \"Tata Motors\", \"Tata Steel\", \"Tech Mahindra\", \"Titan\", \"UltraTech\", \"Phosphorus Limited\", \"Vedanta\", \"Wipro\", \"Zee\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxcuOtVKGtoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "18be43de-20a6-4d3e-eb74-095a366ff3b6"
      },
      "source": [
        "import datetime\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "slist=[]\n",
        "\n",
        "a=datetime.date(2018,1,1)\n",
        "A=a.isoformat()\n",
        "\n",
        "\n",
        "#dffnx.loc[A,'Article']\n",
        "while(a<=datetime.date(2019,12,31)):\n",
        "  if A not in dffnx.index:\n",
        "    \n",
        "    a+=datetime.timedelta(days=1)\n",
        "    A=a.isoformat()\n",
        "    \n",
        "    continue;\n",
        "  article=dffnx.loc[A]\n",
        "  s=''\n",
        "  for x in article['Article']:\n",
        "    noofothers=0\n",
        "    for q in companies:\n",
        "      if(q.lower() in x.lower()):\n",
        "        noofothers+=1\n",
        "    if(noofothers>5):\n",
        "      for q in re.split('\\.\\s+',x):\n",
        "        if ('indian oil corp.' or 'indian oil corporation' or 'indian oil corp' or 'ioc') in q.lower():\n",
        "          s+='\\n'+q+'\\n'\n",
        "    else:\n",
        "      s+=x\n",
        "    # print(s)\n",
        "    # print(\"**********************\")\n",
        "  each_list= nltk.word_tokenize(s)\n",
        "  \n",
        "  WNlemma = nltk.WordNetLemmatizer()\n",
        "  [WNlemma.lemmatize(t) for t in each_list[:-1]]\n",
        "  [t.lower() for t in each_list[:-1]]\n",
        "  slist.append(each_list)\n",
        "  a+=datetime.timedelta(days=1)\n",
        "  A=a.isoformat()\n",
        "  \n",
        "  \n",
        "print(len(slist))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ziheil-Un5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word count\n",
        "import datetime\n",
        "a=datetime.date(2018,1,1)\n",
        "A=a.isoformat()\n",
        "word_list=[]\n",
        "#dffnx.loc[A,'Article']\n",
        "while(a<=datetime.date(2019,12,31)):\n",
        "  if A not in dffnx.index:\n",
        "    a+=datetime.timedelta(days=1)\n",
        "    A=a.isoformat()\n",
        "    word_list.append(0)\n",
        "    continue;\n",
        "  article=dffnx.loc[A]\n",
        "  s=''\n",
        "  for x in article['Article']:\n",
        "    noofothers=0\n",
        "    for q in companies:\n",
        "      if(q.lower() in x.lower()):\n",
        "        noofothers+=1\n",
        "    if(noofothers>5):\n",
        "      for q in re.split('\\.\\s+',x):\n",
        "        if  ('indian oil corp.' or 'indian oil corporation' or 'indian oil corp' or 'ioc') in q.lower():\n",
        "          s+='\\n'+q+'\\n'\n",
        "    else:\n",
        "      s+=x  \n",
        "  each_list= s.split(' ')\n",
        "  word_count=len(each_list)\n",
        " \n",
        "  word_list.append(word_count)\n",
        "  a+=datetime.timedelta(days=1)\n",
        "  A=a.isoformat()\n",
        "wdd_dic={'word count':word_list}  \n",
        "wdd=pd.DataFrame(wdd_dic)\n",
        "wdd.to_csv('word_count_ioc.csv',index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bJBeOBYiCv7t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21925f47-b73b-4796-c840-1cde24a31d96"
      },
      "source": [
        "#word count without 0\n",
        "import datetime\n",
        "a=datetime.date(2018,1,1)\n",
        "A=a.isoformat()\n",
        "word_list1=[]\n",
        "#dffnx.loc[A,'Article']\n",
        "while(a<=datetime.date(2019,12,31)):\n",
        "  if A not in dffnx.index:\n",
        "    a+=datetime.timedelta(days=1)\n",
        "    A=a.isoformat()\n",
        "    \n",
        "    continue;\n",
        "  article=dffnx.loc[A]\n",
        "  s=''\n",
        "  for x in article['Article']:\n",
        "    noofothers=0\n",
        "    for q in companies:\n",
        "      if(q.lower() in x.lower()):\n",
        "        noofothers+=1\n",
        "    if(noofothers>5):\n",
        "      for q in re.split('\\.\\s+',x):\n",
        "        if  ('indian oil corp.' or 'indian oil corporation' or 'indian oil corp' or 'ioc') in q.lower():\n",
        "          s+='\\n'+q+'\\n'\n",
        "    else:\n",
        "      s+=x  \n",
        "  each_list= s.split(' ')\n",
        "  word_count=len(each_list)\n",
        " \n",
        "  word_list1.append(word_count)\n",
        "  a+=datetime.timedelta(days=1)\n",
        "  A=a.isoformat()\n",
        "\n",
        "print(len(word_list1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBeyeTFXzlDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#article count per day\n",
        "\n",
        "a=datetime.date(2018,1,1)\n",
        "A=a.isoformat()\n",
        "pdf_list=[]\n",
        "#dffnx.loc[A,'Article']\n",
        "while(a<=datetime.date(2019,12,31)):\n",
        "  if A not in dffnx.index:\n",
        "    a+=datetime.timedelta(days=1)\n",
        "    A=a.isoformat()\n",
        "    pdf_list.append(0)\n",
        "    continue;\n",
        "  article=dffnx.loc[A,'Article']\n",
        "  mns=pd.Series(article,name='Article')\n",
        "  #print(mns)\n",
        "  pdf=mns.to_frame()\n",
        "  #print(pdf)\n",
        "  msd=len(pdf['Article'])\n",
        "  pdf_list.append(msd)\n",
        " \n",
        "  \n",
        "  a+=datetime.timedelta(days=1)\n",
        "  A=a.isoformat()\n",
        "\n",
        "pdf_dic={'article count': pdf_list}\n",
        "fd= pd.DataFrame(pdf_dic)\n",
        "#print(len(fd))\n",
        "fd.to_csv('article_count_ioc.csv',index=True)    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NRkEvM7Q57x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nncount=[]\n",
        "for z in slist:\n",
        "  ncount=0\n",
        "  for i in nwords:\n",
        "    for j in z:\n",
        "      if(i==j):\n",
        "        ncount=ncount+1\n",
        "  #print(ncount)\n",
        "  nncount.append(ncount)\n",
        "#print(nncount)\n",
        "ecnt_dic={'negative count': nncount}  \n",
        "ecnt=pd.DataFrame(ecnt_dic)\n",
        "ecnt.to_csv('ncount_ioc.csv',index=True)\n",
        " \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW-IXvc3CKLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "nnnp= np.array(nncount)\n",
        "wordnp=np.array(word_list1)\n",
        "pct_np=(nnnp/wordnp)*100\n",
        "pct_list=pct_np.tolist()\n",
        "mny=[]\n",
        "for i in pct_list:\n",
        "  pct= round(i,2)\n",
        "  mny.append(pct)\n",
        "#print(mny)  \n",
        "pct_dic={'pct': mny}\n",
        "pct_df=pd.DataFrame(pct_dic)\n",
        "pct_df.to_csv('pct_ioc.csv',index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6_jTZG4QKrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "companies=[\"Adani\", \"Asian Paints\", \"Axis Bank\", \"Bajaj Auto\", \"Bajaj Finance\", \"Bajaj Finserv\", \"Airtel\", \"Bharti Infratel\", \"BPCL\", \"Britannia\", \"Cipla\", \"Coal India\", \"Reddy\", \"Eicher\", \"GAIL\", \"Grasim\", \"HCL\", \"HDFC\", \"HDFC Bank\", \"Hero Moto\", \"Hindalco\", \"Unilever\", \"ICICI\", \"IndusInd\", \"Infosys\", \"IOC\", \"ITC\", \"JSW\", \"Kotak\", \"Larsen\", \"Mahindra Mahindra\", \"Maruti\", \"Nestle\", \"NTPC\", \"ONGC\", \"PowerGrid\", \"Reliance\", \"Shree Cement\", \"State Bank\", \"Sun Pharma\", \"TCS\", \"Tata Motors\", \"Tata Steel\", \"Tech Mahindra\", \"Titan\", \"UltraTech\", \"Phosphorus Limited\", \"Vedanta\", \"Wipro\", \"Zee\"]\n",
        "dfg=pd.DataFrame(companies)\n",
        "dfg.to_csv('comp.csv',index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WPogC91DT-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
